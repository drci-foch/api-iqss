{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des diff√©rences Python vs R (IQL v7)\n",
    "# \n",
    "## Ce notebook permet d'explorer les cas de divergence entre les r√©sultats Python et R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement des donn√©es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total s√©jours: 2389\n",
      "Colonnes: 58\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier de validation\n",
    "df = pd.read_excel(\"val_py0r7.xlsx\", sheet_name=0)\n",
    "\n",
    "print(f\"Total s√©jours: {len(df)}\")\n",
    "print(f\"Colonnes: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vue d'ensemble des concordances/discordances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONCORDANCE GLOBALE ===\n",
      "\n",
      "pyr_st\n",
      "True     2340\n",
      "False      49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Concordants: 2340\n",
      "Discordants: 49\n",
      "\n",
      "Taux de concordance: 97.9%\n",
      "Taux de discordance: 2.1%\n"
     ]
    }
   ],
   "source": [
    "# Statut de concordance\n",
    "print(\"=== CONCORDANCE GLOBALE ===\\n\")\n",
    "print(df[\"pyr_st\"].value_counts(dropna=False))\n",
    "\n",
    "# M√©thode robuste : convertir en string puis comparer\n",
    "concordants = df[\"pyr_st\"].astype(str).str.upper().eq(\"TRUE\").sum()\n",
    "discordants = df[\"pyr_st\"].astype(str).str.upper().eq(\"FALSE\").sum()\n",
    "total = concordants + discordants\n",
    "\n",
    "print(f\"\\nConcordants: {concordants}\")\n",
    "print(f\"Discordants: {discordants}\")\n",
    "\n",
    "if total > 0:\n",
    "    print(f\"\\nTaux de concordance: {concordants / total * 100:.1f}%\")\n",
    "    print(f\"Taux de discordance: {discordants / total * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MATRICE DE CONFUSION (Python x R) ===\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sej_classe.x'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benysar\\Documents\\GitHub\\api-iqss\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3789\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3791\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:152\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:181\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'sej_classe.x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Matrice de confusion des classes\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== MATRICE DE CONFUSION (Python x R) ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m confusion = pd.crosstab(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msej_classe.x\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.fillna(\u001b[33m\"\u001b[39m\u001b[33mNA\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33msej_classe.y\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33mNA\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     margins=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m     margins_name=\u001b[33m\"\u001b[39m\u001b[33mTotal\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(confusion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benysar\\Documents\\GitHub\\api-iqss\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3893\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3895\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benysar\\Documents\\GitHub\\api-iqss\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3792\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3793\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3794\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3795\u001b[39m     ):\n\u001b[32m   3796\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3797\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3798\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3799\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3800\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'sej_classe.x'"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion des classes\n",
    "print(\"=== MATRICE DE CONFUSION (Python x R) ===\\n\")\n",
    "confusion = pd.crosstab(\n",
    "    df[\"sej_classe.x\"].fillna(\"NA\"),\n",
    "    df[\"sej_classe.y\"].fillna(\"NA\"),\n",
    "    margins=True,\n",
    "    margins_name=\"Total\",\n",
    ")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Documents non retrouv√©s par Python \n",
    "#### Python n'a trouv√© aucun document alors que R en a trouv√© un.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOCUMENTS NON RETROUV√âS PAR PYTHON ===\n",
      "Nombre de cas: 89\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les cas o√π Python = sansLL et R = LL, ET Python n'a pas de doc_id\n",
    "docs_non_trouves = df[\n",
    "    (df[\"sej_classe.x\"] == \"sansLL\")\n",
    "    & (df[\"sej_classe.y\"].isin([\"0j\", \"1j+\"]))\n",
    "    & (df[\"doc_id.x\"].isna())\n",
    "].copy()\n",
    "\n",
    "print(f\"=== DOCUMENTS NON RETROUV√âS PAR PYTHON ===\")\n",
    "print(f\"Nombre de cas: {len(docs_non_trouves)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 üéØ CAUSE A : Borne de date exclusive (31/01 exclu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUTION DES DATES DE VALIDATION ===\n",
      "\n",
      "Docs trouv√©s par Python: 2257\n",
      "\n",
      "Distribution doc_val.x (derniers jours):\n",
      "doc_val.x\n",
      "2025-01-19     43\n",
      "2025-01-20     84\n",
      "2025-01-21     93\n",
      "2025-01-22     97\n",
      "2025-01-23    103\n",
      "2025-01-24    103\n",
      "2025-01-25     60\n",
      "2025-01-26     54\n",
      "2025-01-27     83\n",
      "2025-01-28     97\n",
      "2025-01-29     82\n",
      "2025-01-30     99\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üéØ Docs Python valid√©s le 31/01/2025: 0\n"
     ]
    }
   ],
   "source": [
    "# Analyser la distribution des dates de validation\n",
    "print(\"=== DISTRIBUTION DES DATES DE VALIDATION ===\\n\")\n",
    "\n",
    "# Docs trouv√©s par Python\n",
    "cas_trouves = df[df[\"doc_id.x\"].notna()]\n",
    "print(f\"Docs trouv√©s par Python: {len(cas_trouves)}\")\n",
    "print(\"\\nDistribution doc_val.x (derniers jours):\")\n",
    "print(cas_trouves[\"doc_val.x\"].value_counts().sort_index().tail(12))\n",
    "\n",
    "# V√©rifier le 31/01\n",
    "docs_31_jan_py = cas_trouves[cas_trouves[\"doc_val.x\"] == \"2025-01-31\"]\n",
    "print(f\"\\nüéØ Docs Python valid√©s le 31/01/2025: {len(docs_31_jan_py)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATES DE VALIDATION DES DOCS R NON TROUV√âS ===\n",
      "\n",
      "doc_val.y\n",
      "2025-01-31    53\n",
      "2025-02-03     1\n",
      "2025-02-04     2\n",
      "2025-02-06     6\n",
      "2025-02-07     2\n",
      "2025-02-08     6\n",
      "2025-02-11     1\n",
      "2025-02-13     2\n",
      "2025-02-14     5\n",
      "2025-02-16     2\n",
      "2025-02-17     1\n",
      "2025-02-18     2\n",
      "2025-02-19     1\n",
      "2025-03-06     1\n",
      "2025-04-25     1\n",
      "2025-05-07     2\n",
      "2025-09-22     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä R√©partition:\n",
      "  - Doc valid√© le 31/01/2025 (BORNE EXCLUE):  53 cas\n",
      "  - Doc valid√© APR√àS 31/01/2025 (hors p√©riode): 36 cas\n"
     ]
    }
   ],
   "source": [
    "# Docs R du 31/01 non trouv√©s par Python\n",
    "docs_non_trouves[\"doc_val_date\"] = pd.to_datetime(docs_non_trouves[\"doc_val.y\"]).dt.date\n",
    "\n",
    "print(\"=== DATES DE VALIDATION DES DOCS R NON TROUV√âS ===\\n\")\n",
    "print(docs_non_trouves[\"doc_val.y\"].value_counts().sort_index())\n",
    "\n",
    "# S√©parer par date\n",
    "cause_a_31jan = docs_non_trouves[docs_non_trouves[\"doc_val.y\"] == \"2025-01-31\"]\n",
    "cause_a_apres = docs_non_trouves[docs_non_trouves[\"doc_val.y\"] > \"2025-01-31\"]\n",
    "\n",
    "print(f\"\\nüìä R√©partition:\")\n",
    "print(f\"  - Doc valid√© le 31/01/2025 (BORNE EXCLUE):  {len(cause_a_31jan)} cas\")\n",
    "print(f\"  - Doc valid√© APR√àS 31/01/2025 (hors p√©riode): {len(cause_a_apres)} cas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 CAUSE B : Documents valid√©s apr√®s la p√©riode demand√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAUSE B : DOCUMENTS VALID√âS APR√àS LA P√âRIODE (36 cas)\n",
      "============================================================\n",
      "\n",
      "Nombre de cas: 36\n",
      "\n",
      "Distribution des dates de validation (apr√®s p√©riode):\n",
      "doc_val.y\n",
      "2025-02-03    1\n",
      "2025-02-04    2\n",
      "2025-02-06    6\n",
      "2025-02-07    2\n",
      "2025-02-08    6\n",
      "2025-02-11    1\n",
      "2025-02-13    2\n",
      "2025-02-14    5\n",
      "2025-02-16    2\n",
      "2025-02-17    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  - R a trouv√© via doc_venue: 30\n",
      "  - R a trouv√© sans doc_venue: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CAUSE B : DOCUMENTS VALID√âS APR√àS LA P√âRIODE (36 cas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNombre de cas: {len(cause_a_apres)}\")\n",
    "\n",
    "# Analyser ces cas\n",
    "print(\"\\nDistribution des dates de validation (apr√®s p√©riode):\")\n",
    "print(cause_a_apres[\"doc_val.y\"].value_counts().sort_index().head(10))\n",
    "\n",
    "# V√©rifier si doc_venue correspond\n",
    "avec_venue = cause_a_apres[cause_a_apres[\"doc_venue.y\"].notna()]\n",
    "sans_venue = cause_a_apres[cause_a_apres[\"doc_venue.y\"].isna()]\n",
    "print(f\"\\n  - R a trouv√© via doc_venue: {len(avec_venue)}\")\n",
    "print(f\"  - R a trouv√© sans doc_venue: {len(sans_venue)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CAUSE C : Doc Python sans sp√©cialit√© (57 cas)\n",
    " \n",
    "#### Python a trouv√© un document mais la jointure avec la matrice n'a pas donn√© de sp√©cialit√©, alors que R a trouv√© un AUTRE document avec sp√©cialit√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéØ CAUSE C : DOC PYTHON SANS SP√âCIALIT√â (57 cas)\n",
      "============================================================\n",
      "\n",
      "Nombre de cas: 57\n",
      "\n",
      "PROBL√àME IDENTIFI√â:\n",
      "- Python trouve un doc (ex: \"CR Urgences\") mais sans sp√©cialit√© dans la matrice\n",
      "- R trouve un AUTRE doc (ex: \"CR LL Cardiologie\") avec sp√©cialit√©\n",
      "- La jointure matrice est faite APR√àS le tri en Python, AVANT en R\n",
      "\n",
      "SOLUTION (src/data_processing.py):\n",
      "  Faire la jointure matrice AVANT le tri, comme en R (ligne 184)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les cas o√π Python a un doc mais pas de sp√©cialit√©\n",
    "cause_c = df[\n",
    "    (df[\"sej_classe.x\"] == \"sansLL\")\n",
    "    & (df[\"sej_classe.y\"].isin([\"0j\", \"1j+\"]))\n",
    "    & (df[\"doc_id.x\"].notna())\n",
    "    & (df[\"sej_spe.x\"].isna())\n",
    "].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ CAUSE C : DOC PYTHON SANS SP√âCIALIT√â (57 cas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNombre de cas: {len(cause_c)}\")\n",
    "print(\"\"\"\n",
    "PROBL√àME IDENTIFI√â:\n",
    "- Python trouve un doc (ex: \"CR Urgences\") mais sans sp√©cialit√© dans la matrice\n",
    "- R trouve un AUTRE doc (ex: \"CR LL Cardiologie\") avec sp√©cialit√©\n",
    "- La jointure matrice est faite APR√àS le tri en Python, AVANT en R\n",
    "\n",
    "SOLUTION (src/data_processing.py):\n",
    "  Faire la jointure matrice AVANT le tri, comme en R (ligne 184)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Types de documents Python sans mapping ===\n",
      "\n",
      "doc_libelle.x\n",
      "CR Urgences                                                  42\n",
      "CR HDJ Oncologie Foch                                         4\n",
      "CR Lettre de Liaison R√©a Foch                                 4\n",
      "CR Lettre de Liaison Pneumologie Foch                         2\n",
      "CR Lettre de Liaison M√©decine interne et Polyvalente Foch     1\n",
      "CR Lettre de Liaison M√©decine Interne Foch                    1\n",
      "CR Lettre de Liaison Oncologie HDJ ILR Foch                   1\n",
      "CR Lettre de Liaison Cardiologie Foch                         1\n",
      "CR Lettre de Liaison HDJ Education Diab√©tologie Foch          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Comparaison Python vs R ===\n",
      "\n",
      "         sej_id  sej_uf.x                                              doc_libelle.x sej_spe.x                                   doc_libelle.y         sej_spe.y\n",
      "2     240281460       338                                      CR HDJ Oncologie Foch       NaN     CR Lettre de Liaison Unit√© Vanderbilt Foch         VANDERBILT\n",
      "46    240378713       338                                      CR HDJ Oncologie Foch       NaN     CR Lettre de Liaison Unit√© Vanderbilt Foch         VANDERBILT\n",
      "84    240386844       338                                      CR HDJ Oncologie Foch       NaN     CR Lettre de Liaison Unit√© Vanderbilt Foch         VANDERBILT\n",
      "164   249050332       330                              CR Lettre de Liaison R√©a Foch       NaN           CR Lettre de Liaison Pneumologie Foch       PNEUMOLOGIE\n",
      "272   249053689       438                                                CR Urgences       NaN                CR Lettre de liaison Foch. USINV        NEUROLOGIE\n",
      "302   250000201       396                                                CR Urgences       NaN  CR Lettre de Liaison Chirurgie Urologique Foch          UROLOGIE\n",
      "539   250001593       396                                                CR Urgences       NaN  CR Lettre de Liaison Chirurgie Urologique Foch          UROLOGIE\n",
      "884   250010933       339  CR Lettre de Liaison M√©decine interne et Polyvalente Foch       NaN           CR Lettre de Liaison Psychiatrie Foch       PSYCHIATRIE\n",
      "1128  250019625       438                 CR Lettre de Liaison M√©decine Interne Foch       NaN            CR Lettre de Liaison Neurologie Foch        NEUROLOGIE\n",
      "1200  250021240       336                              CR Lettre de Liaison R√©a Foch       NaN     CR Lettre de Liaison M√©decine Interne Foch   MEDECINE INTERNE\n",
      "1240  250022905       396                CR Lettre de Liaison Oncologie HDJ ILR Foch       NaN  CR Lettre de Liaison Chirurgie Urologique Foch          UROLOGIE\n",
      "1259  250023178       437                              CR Lettre de Liaison R√©a Foch       NaN                CR Lettre de liaison Foch. USINV        NEUROLOGIE\n",
      "1306  250026511       437                      CR Lettre de Liaison Pneumologie Foch       NaN            CR Lettre de Liaison Neurologie Foch        NEUROLOGIE\n",
      "1331  250028013       336                      CR Lettre de Liaison Pneumologie Foch       NaN     CR Lettre de Liaison M√©decine Interne Foch   MEDECINE INTERNE\n",
      "1334  250028146       372                                                CR Urgences       NaN  CR Lettre de Liaison Chirurgie Vasculaire Foch        VASCULAIRE\n"
     ]
    }
   ],
   "source": [
    "# Types de documents Python sans mapping\n",
    "print(\"\\n=== Types de documents Python sans mapping ===\\n\")\n",
    "print(cause_c[\"doc_libelle.x\"].value_counts())\n",
    "\n",
    "# %%\n",
    "# Comparaison doc Python vs doc R\n",
    "print(\"\\n=== Comparaison Python vs R ===\\n\")\n",
    "cols_c = [\n",
    "    \"sej_id\",\n",
    "    \"sej_uf.x\",\n",
    "    \"doc_libelle.x\",\n",
    "    \"sej_spe.x\",\n",
    "    \"doc_libelle.y\",\n",
    "    \"sej_spe.y\",\n",
    "]\n",
    "print(cause_c[cols_c].head(15).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CAUSE D : Documents diff√©rents s√©lectionn√©s (21 cas avec sp√©cialit√©)\n",
    " \n",
    "#### Python et R ont tous deux trouv√© un document avec sp√©cialit√©, mais pas le m√™me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAUSE D : DOCUMENTS DIFF√âRENTS S√âLECTIONN√âS (21 cas)\n",
      "============================================================\n",
      "\n",
      "Nombre de cas: 21\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les cas o√π doc_id diff√®re ET Python a une sp√©cialit√©\n",
    "cause_d = df[\n",
    "    (df[\"doc_id.x\"] != df[\"doc_id.y\"])\n",
    "    & (df[\"doc_id.x\"].notna())\n",
    "    & (df[\"doc_id.y\"].notna())\n",
    "    & (df[\"sej_spe.x\"].notna())\n",
    "].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CAUSE D : DOCUMENTS DIFF√âRENTS S√âLECTIONN√âS (21 cas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNombre de cas: {len(cause_d)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparaison des crit√®res de s√©lection ===\n",
      "\n",
      "Crit√®re      |  Python True |       R True\n",
      "------------------------------------------\n",
      "sdt_docven   |            0 |           20\n",
      "sdt_docval   |            8 |           20\n",
      "sdt_smere    |           17 |           19\n",
      "sdt_doccre   |           12 |           21\n",
      "sdt_doccref  |            3 |           14\n",
      "sdt_emere    |           14 |           21\n",
      "sdt_status   |            4 |           18\n",
      "\n",
      "=== Exemples docs diff√©rents ===\n",
      "\n",
      "         sej_id  sej_uf.x    doc_id.x         sej_spe.x  del_sorval.x  sdt_docven.x    doc_id.y         sej_spe.y  del_sorval.y sdt_docven.y\n",
      "344   250000418       396  39111841.0          UROLOGIE           NaN         False  39276570.0          UROLOGIE          31.0         True\n",
      "615   250002688       396  38945580.0          UROLOGIE          13.0         False  39169683.0          UROLOGIE          24.0         True\n",
      "700   250004795       330  38862568.0       PNEUMOLOGIE          -1.0         False  39752405.0       PNEUMOLOGIE           NaN        False\n",
      "802   250007617       399  39113930.0       NEPHROLOGIE          -2.0         False  39076038.0       NEPHROLOGIE         109.0         True\n",
      "843   250009287       351  39019117.0       GYNECOLOGIE          -1.0         False  39028406.0       GYNECOLOGIE           0.0         True\n",
      "937   250012510       396  39003596.0          UROLOGIE           NaN         False  39223833.0          UROLOGIE          20.0         True\n",
      "1130  250019673       408  39070083.0       CARDIOLOGIE           NaN         False  39169158.0       CARDIOLOGIE           0.0         True\n",
      "1157  250020824       408  39072298.0       CARDIOLOGIE           NaN         False  39169410.0       CARDIOLOGIE           0.0         True\n",
      "1239  250022899       399  39064546.0       NEPHROLOGIE           NaN         False  39120623.0       NEPHROLOGIE          20.0         True\n",
      "1271  250024627       336  39158601.0  MEDECINE INTERNE           NaN         False  39196327.0  MEDECINE INTERNE          10.0         True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Comparaison des crit√®res de s√©lection ===\\n\")\n",
    "print(f\"{'Crit√®re':<12} | {'Python True':>12} | {'R True':>12}\")\n",
    "print(\"-\" * 42)\n",
    "print(\n",
    "    f\"{'sdt_docven':<12} | {cause_d['sdt_docven.x'].sum():>12} | {cause_d['sdt_docven.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_docval':<12} | {cause_d['sdt_docval.x'].sum():>12} | {cause_d['sdt_docval.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_smere':<12} | {cause_d['sdt_smere.x'].sum():>12} | {cause_d['sdt_smere.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_doccre':<12} | {cause_d['sdt_doccre.x'].sum():>12} | {cause_d['sdt_doccre.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_doccref':<12} | {cause_d['sdt_doccref.x'].sum():>12} | {cause_d['sdt_doccref.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_emere':<12} | {cause_d['sdt_emere.x'].sum():>12} | {cause_d['sdt_emere.y'].sum():>12}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'sdt_status':<12} | {cause_d['sdt_status.x'].sum():>12} | {cause_d['sdt_status.y'].sum():>12}\"\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Exemples\n",
    "print(\"\\n=== Exemples docs diff√©rents ===\\n\")\n",
    "cols_d = [\n",
    "    \"sej_id\",\n",
    "    \"sej_uf.x\",\n",
    "    \"doc_id.x\",\n",
    "    \"sej_spe.x\",\n",
    "    \"del_sorval.x\",\n",
    "    \"sdt_docven.x\",\n",
    "    \"doc_id.y\",\n",
    "    \"sej_spe.y\",\n",
    "    \"del_sorval.y\",\n",
    "    \"sdt_docven.y\",\n",
    "]\n",
    "print(cause_d[cols_d].head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. CAUSE E : Python=LL mais R=sansLL (8 cas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CAUSE E : PYTHON=LL MAIS R=SANSLL (8 cas)\n",
      "============================================================\n",
      "\n",
      "Nombre de cas: 8\n",
      "         sej_id  sej_uf.x    doc_id.x                               doc_libelle.x         sej_spe.x  del_val.x sej_classe.x    doc_id.y         sej_spe.y  del_val.y sej_classe.y\n",
      "700   250004795       330  38862568.0       CR Lettre de Liaison Pneumologie Foch       PNEUMOLOGIE        0.0           0j  39752405.0       PNEUMOLOGIE        NaN       sansLL\n",
      "833   250009057       456  38967293.0       CR Lettre de Liaison Pneumologie Foch       PNEUMOLOGIE        0.0           0j  38967293.0       PNEUMOLOGIE        NaN       sansLL\n",
      "1457  259000120       324  38995702.0         CR Lettre de Liaison Oncologie Foch         ONCOLOGIE        0.0           0j  39137232.0         ONCOLOGIE        NaN       sansLL\n",
      "1490  259000313       390  39022099.0               CR Lettre de Liaison ORL Foch               ORL        0.0           0j  39022099.0               ORL        NaN       sansLL\n",
      "1722  259001483       336  39154836.0  CR Lettre de Liaison M√©decine Interne Foch  MEDECINE INTERNE        0.0           0j  39041125.0  MEDECINE INTERNE        NaN       sansLL\n",
      "1724  259001485       423  39039312.0       CR Lettre de Liaison Cardiologie Foch       CARDIOLOGIE        0.0           0j  39039312.0       CARDIOLOGIE        NaN       sansLL\n",
      "2078  259003339       423  39113531.0              CR Lettre de Liaison UPHU Foch              UPHU        0.0           0j  39113531.0              UPHU        NaN       sansLL\n",
      "2156  259003644       423  39043919.0              CR Lettre de Liaison UPHU Foch              UPHU        0.0           0j  39043919.0              UPHU        NaN       sansLL\n"
     ]
    }
   ],
   "source": [
    "cause_e = df[\n",
    "    (df[\"sej_classe.x\"].isin([\"0j\", \"1j+\"])) & (df[\"sej_classe.y\"] == \"sansLL\")\n",
    "].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CAUSE E : PYTHON=LL MAIS R=SANSLL (8 cas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNombre de cas: {len(cause_e)}\")\n",
    "\n",
    "if len(cause_e) > 0:\n",
    "    cols_e = [\n",
    "        \"sej_id\",\n",
    "        \"sej_uf.x\",\n",
    "        \"doc_id.x\",\n",
    "        \"doc_libelle.x\",\n",
    "        \"sej_spe.x\",\n",
    "        \"del_val.x\",\n",
    "        \"sej_classe.x\",\n",
    "        \"doc_id.y\",\n",
    "        \"sej_spe.y\",\n",
    "        \"del_val.y\",\n",
    "        \"sej_classe.y\",\n",
    "    ]\n",
    "    print(cause_e[cols_e].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. R√©sum√© des causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä R√âSUM√â DES CAUSES DE DIVERGENCE\n",
      "======================================================================\n",
      "\n",
      "Total discordants: 175\n",
      "\n",
      "Cause                                         |    Nb |      %\n",
      "--------------------------------------------------------------\n",
      "A. Borne date exclusive (31/01 exclu)         |    53 |  30.3%\n",
      "B. Docs valid√©s apr√®s p√©riode                 |    36 |  20.6%\n",
      "C. Doc Python sans sp√©cialit√© (tri)           |    57 |  32.6%\n",
      "D. Docs diff√©rents (autres crit√®res)          |    21 |  12.0%\n",
      "E. Python=LL, R=sansLL                        |     8 |   4.6%\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üìä R√âSUM√â DES CAUSES DE DIVERGENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Recalculer les totaux\n",
    "total_discordants = discordants\n",
    "\n",
    "print(f\"\\nTotal discordants: {total_discordants}\\n\")\n",
    "print(f\"{'Cause':<45} | {'Nb':>5} | {'%':>6}\")\n",
    "print(\"-\" * 62)\n",
    "print(\n",
    "    f\"{'A. Borne date exclusive (31/01 exclu)':<45} | {len(cause_a_31jan):>5} | {len(cause_a_31jan) / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'B. Docs valid√©s apr√®s p√©riode':<45} | {len(cause_a_apres):>5} | {len(cause_a_apres) / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'C. Doc Python sans sp√©cialit√© (tri)':<45} | {len(cause_c):>5} | {len(cause_c) / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'D. Docs diff√©rents (autres crit√®res)':<45} | {len(cause_d):>5} | {len(cause_d) / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"{'E. Python=LL, R=sansLL':<45} | {len(cause_e):>5} | {len(cause_e) / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "print(\"-\" * 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EXPLIQU√â                                |   175 | 100.0%\n"
     ]
    }
   ],
   "source": [
    "total_explique = (\n",
    "    len(cause_a_31jan) + len(cause_a_apres) + len(cause_c) + len(cause_d) + len(cause_e)\n",
    ")\n",
    "print(\n",
    "    f\"{'TOTAL EXPLIQU√â':<45} | {total_explique:>5} | {total_explique / total_discordants * 100:>5.1f}%\"\n",
    ")\n",
    "\n",
    "non_explique = total_discordants - total_explique\n",
    "if non_explique > 0:\n",
    "    print(\n",
    "        f\"{'Non expliqu√©':<45} | {non_explique:>5} | {non_explique / total_discordants * 100:>5.1f}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Export des cas pour analyse manuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier 'analyse_causes_divergence.xlsx' cr√©√© avec les cas par cause\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"analyse_causes_divergence.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    cause_a_31jan.to_excel(writer, sheet_name=\"CauseA_Borne31jan\", index=False)\n",
    "    cause_a_apres.to_excel(writer, sheet_name=\"CauseB_ApresPerdiode\", index=False)\n",
    "    cause_c.to_excel(writer, sheet_name=\"CauseC_DocSansSpe\", index=False)\n",
    "    cause_d.to_excel(writer, sheet_name=\"CauseD_DocDifferent\", index=False)\n",
    "    if len(cause_e) > 0:\n",
    "        cause_e.to_excel(writer, sheet_name=\"CauseE_PyLL_RsansLL\", index=False)\n",
    "\n",
    "print(\"‚úÖ Fichier 'analyse_causes_divergence.xlsx' cr√©√© avec les cas par cause\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
